06/27 18:20:46 - mmengine - [4m[97mINFO[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.
06/27 18:20:46 - mmengine - [4m[97mINFO[0m - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook
(BELOW_NORMAL) LoggerHook
 --------------------
before_train:
(VERY_HIGH   ) RuntimeInfoHook
(NORMAL      ) IterTimerHook
(VERY_LOW    ) CheckpointHook
 --------------------
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook
(NORMAL      ) IterTimerHook
(NORMAL      ) DistSamplerSeedHook
 --------------------
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook
(NORMAL      ) IterTimerHook
 --------------------
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook
(NORMAL      ) IterTimerHook
(BELOW_NORMAL) LoggerHook
(LOW         ) ParamSchedulerHook
(VERY_LOW    ) CheckpointHook
 --------------------
after_train_epoch:
(NORMAL      ) IterTimerHook
(LOW         ) ParamSchedulerHook
(VERY_LOW    ) CheckpointHook
 --------------------
before_val:
(VERY_HIGH   ) RuntimeInfoHook
 --------------------
before_val_epoch:
(NORMAL      ) IterTimerHook
 --------------------
before_val_iter:
(NORMAL      ) IterTimerHook
 --------------------
after_val_iter:
(NORMAL      ) IterTimerHook
(NORMAL      ) TanmlhVisualizationHook
(BELOW_NORMAL) LoggerHook
 --------------------
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook
(NORMAL      ) IterTimerHook
(BELOW_NORMAL) LoggerHook
(LOW         ) ParamSchedulerHook
(VERY_LOW    ) CheckpointHook
 --------------------
after_val:
(VERY_HIGH   ) RuntimeInfoHook
 --------------------
after_train:
(VERY_HIGH   ) RuntimeInfoHook
(VERY_LOW    ) CheckpointHook
 --------------------
before_test:
(VERY_HIGH   ) RuntimeInfoHook
 --------------------
before_test_epoch:
(NORMAL      ) IterTimerHook
 --------------------
before_test_iter:
(NORMAL      ) IterTimerHook
 --------------------
after_test_iter:
(NORMAL      ) IterTimerHook
(NORMAL      ) TanmlhVisualizationHook
(BELOW_NORMAL) LoggerHook
 --------------------
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook
(NORMAL      ) IterTimerHook
(BELOW_NORMAL) LoggerHook
 --------------------
after_test:
(VERY_HIGH   ) RuntimeInfoHook
 --------------------
after_run:
(BELOW_NORMAL) LoggerHook
 --------------------
loading annotations into memory...
Done (t=0.62s)
creating index...
index created!
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.0.downsample.0.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.downsample.1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.0.downsample.1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.1.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.1.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.1.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.1.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.1.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.1.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.1.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.2.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.2.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.2.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.2.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer1.2.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.2.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer1.2.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.0.downsample.0.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.downsample.1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.0.downsample.1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.1.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.1.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.1.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.1.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.1.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.1.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.1.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.2.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.2.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.2.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.2.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.2.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.2.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.2.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.3.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.3.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.3.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.3.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer2.3.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.3.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer2.3.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.0.downsample.0.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.downsample.1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.0.downsample.1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.1.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.1.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.1.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.1.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.1.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.1.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.1.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.2.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.2.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.2.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.2.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.2.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.2.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.2.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.3.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.3.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.3.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.3.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.3.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.3.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.3.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.4.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.4.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.4.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.4.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.4.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.4.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.4.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.5.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.5.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.5.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.5.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer3.5.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.5.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer3.5.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.0.downsample.0.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.downsample.1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.0.downsample.1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.1.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.1.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.1.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.1.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.1.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.1.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.1.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv1.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv1.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv1.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv1.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.2.bn1.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.2.bn1.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv2.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv2.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv2.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv2.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.2.bn2.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.2.bn2.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv3.weight:lr=1.0000000000000001e-07
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv3.weight:weight_decay=0.05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv3.weight:lr_mult=0.01
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- backbone.layer4.2.conv3.weight:decay_mult=1.0
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.2.bn3.weight is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [5m[4m[33mWARNING[0m - backbone.layer4.2.bn3.bias is skipped since its requires_grad=False
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.input_convs.0.gn.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.input_convs.0.gn.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.input_convs.1.gn.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.input_convs.1.gn.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.input_convs.2.gn.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.input_convs.2.gn.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.0.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.0.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.0.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.0.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.1.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.1.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.1.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.1.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.2.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.2.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.2.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.2.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.3.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.3.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.3.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.3.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.4.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.4.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.4.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.4.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.5.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.5.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.5.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.encoder.layers.5.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.lateral_convs.0.gn.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.lateral_convs.0.gn.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.output_convs.0.gn.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.pixel_decoder.output_convs.0.gn.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.0.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.0.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.0.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.0.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.0.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.0.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.1.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.1.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.1.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.1.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.1.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.1.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.2.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.2.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.2.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.2.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.2.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.2.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.3.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.3.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.3.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.3.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.3.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.3.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.4.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.4.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.4.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.4.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.4.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.4.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.5.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.5.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.5.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.5.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.5.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.5.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.6.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.6.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.6.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.6.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.6.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.6.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.7.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.7.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.7.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.7.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.7.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.7.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.8.norms.0.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.8.norms.0.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.8.norms.1.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.8.norms.1.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.8.norms.2.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.layers.8.norms.2.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.post_norm.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.transformer_decoder.post_norm.bias:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_embed.weight:lr=1e-05
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_embed.weight:weight_decay=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_embed.weight:lr_mult=1.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_embed.weight:decay_mult=0.0
06/27 18:20:47 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_feat.weight:lr=1e-05
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_feat.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_feat.weight:lr_mult=1.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.query_feat.weight:decay_mult=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.level_embed.weight:lr=1e-05
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.level_embed.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.level_embed.weight:lr_mult=1.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.level_embed.weight:decay_mult=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.mask_feat_proj.1.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.mask_feat_proj.1.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.mask_feat_proj.4.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.mask_feat_proj.4.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.0.norms.0.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.0.norms.0.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.0.norms.1.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.0.norms.1.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.0.norms.2.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.0.norms.2.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.1.norms.0.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.1.norms.0.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.1.norms.1.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.1.norms.1.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.1.norms.2.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.1.norms.2.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.2.norms.0.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.2.norms.0.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.2.norms.1.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.2.norms.1.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.2.norms.2.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.layers.2.norms.2.bias:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.post_norm.weight:weight_decay=0.0
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - paramwise_options -- panoptic_head.dp_polygonize_head.decoder.post_norm.bias:weight_decay=0.0
loading annotations into memory...
Done (t=0.03s)
creating index...
index created!
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Frozen parameters: ['backbone', 'panoptic_head.pixel_decoder', 'panoptic_head.transformer_decoder', 'panoptic_head.decoder_input_projs', 'panoptic_head.query_embed', 'panoptic_head.query_feat', 'panoptic_head.level_embed', 'panoptic_head.cls_embed', 'panoptic_head.mask_embed']
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.3.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.3.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.4.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.4.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.6.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.mask_feat_proj.6.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.in_proj_weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.in_proj_bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.out_proj.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.out_proj.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.in_proj_weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.in_proj_bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.out_proj.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.out_proj.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.0.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.0.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.norms.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.norms.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.norms.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.norms.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.norms.2.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.0.norms.2.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.in_proj_weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.in_proj_bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.out_proj.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.out_proj.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.in_proj_weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.in_proj_bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.out_proj.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.out_proj.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.0.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.0.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.norms.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.norms.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.norms.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.norms.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.norms.2.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.1.norms.2.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.in_proj_weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.in_proj_bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.out_proj.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.out_proj.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.in_proj_weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.in_proj_bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.out_proj.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.out_proj.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.0.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.0.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.norms.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.norms.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.norms.1.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.norms.1.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.norms.2.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.layers.2.norms.2.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.post_norm.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.decoder.post_norm.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_reg_head.0.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_reg_head.0.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_reg_head.2.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_reg_head.2.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_reg_head.4.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_reg_head.4.bias
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_embed.weight
06/27 18:20:48 - mmengine - [4m[97mINFO[0m - Training parameters: panoptic_head.dp_polygonize_head.poly_embed.bias
Loads checkpoint by local backend from path: checkpoints/mask2former_e10_lre-5_kostanai-afs_v1.pth
The model and loaded state dict do not match exactly

missing keys in source state_dict: panoptic_head.mask_feat_proj.0.weight, panoptic_head.mask_feat_proj.0.bias, panoptic_head.mask_feat_proj.1.weight, panoptic_head.mask_feat_proj.1.bias, panoptic_head.mask_feat_proj.1.running_mean, panoptic_head.mask_feat_proj.1.running_var, panoptic_head.mask_feat_proj.3.weight, panoptic_head.mask_feat_proj.3.bias, panoptic_head.mask_feat_proj.4.weight, panoptic_head.mask_feat_proj.4.bias, panoptic_head.mask_feat_proj.4.running_mean, panoptic_head.mask_feat_proj.4.running_var, panoptic_head.mask_feat_proj.6.weight, panoptic_head.mask_feat_proj.6.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.in_proj_weight, panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.in_proj_bias, panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.out_proj.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.self_attn.attn.out_proj.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.in_proj_weight, panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.in_proj_bias, panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.out_proj.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.cross_attn.attn.out_proj.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.0.0.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.0.0.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.1.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.ffn.layers.1.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.norms.0.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.norms.0.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.norms.1.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.norms.1.bias, panoptic_head.dp_polygonize_head.decoder.layers.0.norms.2.weight, panoptic_head.dp_polygonize_head.decoder.layers.0.norms.2.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.in_proj_weight, panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.in_proj_bias, panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.out_proj.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.self_attn.attn.out_proj.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.in_proj_weight, panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.in_proj_bias, panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.out_proj.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.cross_attn.attn.out_proj.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.0.0.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.0.0.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.1.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.ffn.layers.1.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.norms.0.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.norms.0.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.norms.1.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.norms.1.bias, panoptic_head.dp_polygonize_head.decoder.layers.1.norms.2.weight, panoptic_head.dp_polygonize_head.decoder.layers.1.norms.2.bias, panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.in_proj_weight, panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.in_proj_bias, panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.out_proj.weight, panoptic_head.dp_polygonize_head.decoder.layers.2.self_attn.attn.out_proj.bias, panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.in_proj_weight, panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.in_proj_bias, panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.out_proj.weight, panoptic_head.dp_polygonize_head.decoder.layers.2.cross_attn.attn.out_proj.bias, panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.0.0.weight, panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.0.0.bias, panoptic_head.dp_polygonize_head.decoder.layers.2.ffn.layers.1.weig

06/27 18:20:49 - mmengine - [4m[97mINFO[0m - Load checkpoint from checkpoints/mask2former_e10_lre-5_kostanai-afs_v1.pth
06/27 18:20:49 - mmengine - [5m[4m[33mWARNING[0m - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
06/27 18:20:49 - mmengine - [5m[4m[33mWARNING[0m - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
06/27 18:20:49 - mmengine - [4m[97mINFO[0m - Checkpoints will be saved to D:\Sagi\GCP\GCP\work_dir\gcp_training\gcp_e5_lre-5_kostanai_afs_v1.
C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\torch\functional.py:507: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ..\aten\src\ATen\native\TensorShape.cpp:3550.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5DE0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5DE0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5DE0>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5DE0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5DE0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5DE0>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5630>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5630>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5630>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5630>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5630>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744AE5630>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2EF80>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2EF80>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2EF80>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2EF80>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2EF80>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2EF80>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F0A0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F0A0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F0A0>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F0A0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F0A0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F0A0>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F1F0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F1F0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F1F0>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F1F0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F1F0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F1F0>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E1A0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E1A0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E1A0>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E1A0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E1A0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E1A0>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2DBD0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2DBD0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2DBD0>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2DBD0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2DBD0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2DBD0>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E3B0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E3B0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E3B0>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E3B0>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E3B0>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2E3B0>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F730>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F730>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F730>
loss_poly requires_grad: False, grad_fn: None
loss_dp requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F730>
loss_poly_reg requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F730>
loss_poly_ang requires_grad: True, grad_fn: <MulBackward0 object at 0x0000021744B2F730>
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Returning Normal Case Losses:
loss_cls requires_grad: False, grad_fn: None
loss_mask requires_grad: False, grad_fn: None
loss_dice requires_grad: False, grad_fn: None
loss_poly requires_grad: False, grad_fn: None
Traceback (most recent call last):
  File "D:\Sagi\GCP\GCP\tools\train.py", line 170, in <module>
    main()
  File "D:\Sagi\GCP\GCP\tools\train.py", line 166, in main
    runner.train()
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\mmengine\runner\runner.py", line 1777, in train
    model = self.train_loop.run()  # type: ignore
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\mmengine\runner\loops.py", line 98, in run
    self.run_epoch()
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\mmengine\runner\loops.py", line 115, in run_epoch
    self.run_iter(idx, data_batch)
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\mmengine\runner\loops.py", line 131, in run_iter
    outputs = self.runner.model.train_step(
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\mmengine\model\base_model\base_model.py", line 114, in train_step
    losses = self._run_forward(data, mode='loss')  # type: ignore
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\mmengine\model\base_model\base_model.py", line 361, in _run_forward
    results = self(**data, mode=mode)
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\torch\nn\modules\module.py", line 1511, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "C:\Users\Sagi\Miniconda3\envs\gcp-env\lib\site-packages\torch\nn\modules\module.py", line 1520, in _call_impl
    return forward_call(*args, **kwargs)
  File "D:\Sagi\GCP\GCP\mmdet\models\detectors\base.py", line 94, in forward
    return self.loss(inputs, data_samples)
  File "D:\Sagi\GCP\GCP\mmdet\models\detectors\maskformer.py", line 64, in loss
    losses = self.panoptic_head.loss(x, batch_data_samples)
  File "D:\Sagi\GCP\GCP\mmdet\models\dense_heads\polygonizer_head.py", line 405, in loss
    losses = self.loss_by_feat(pred_results, batch_gt_instances, batch_img_metas)
  File "D:\Sagi\GCP\GCP\mmdet\models\dense_heads\polygonizer_head.py", line 448, in loss_by_feat
    losses = multi_apply_v2(
  File "D:\Sagi\GCP\GCP\mmdet\models\utils\misc.py", line 249, in multi_apply_v2
    cur_result = func(*new_args, **new_kwargs)
  File "D:\Sagi\GCP\GCP\mmdet\models\dense_heads\polygonizer_head.py", line 681, in _loss_by_feat_single
    losses_poly = self.dp_polygonize_head.loss(
  File "D:\Sagi\GCP\GCP\mmdet\models\dense_heads\dp_polygonize_head.py", line 184, in loss
    max_diff = (pred_angle[cur_mask] - target_angle[cur_mask]).abs().max()
KeyboardInterrupt
